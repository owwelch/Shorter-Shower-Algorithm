{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e96599c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#note: temp readings are 20s apart\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Normalization\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "246083b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('data_flattened')\n",
    "files = os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "095c4bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allocate_data(training_files):\n",
    "    dfs = {}\n",
    "    for file in training_files:\n",
    "        df = pd.read_excel(file, sheet_name=\"DATA\", usecols='C,D', skiprows = 1)\n",
    "        df.columns = ['temp', 'label']\n",
    "        df.loc[df.shape[0]] = [None, None]# to ensure that there are breaks between each recorded shower\n",
    "        dfs[file] = df\n",
    "    data = pd.concat(list(dfs.values()), ignore_index = True)# concatenating all our data into one big dataframe\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3163c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(data, model_type):\n",
    "    if model_type == 'Start':\n",
    "        window_size = 19\n",
    "    elif model_type == 'End':\n",
    "        window_size = 25\n",
    "    #list where the first item is 1 for model_type and 0 for not model_type:\n",
    "    pts = []\n",
    "\n",
    "    for i, row in data.iterrows():\n",
    "        if not pd.isnull(row['label']):\n",
    "            if row['label'].startswith(model_type):\n",
    "                pts.append([1] + data.iloc[i-window_size//2:i+window_size//2+1]['temp'].tolist())\n",
    "\n",
    "    initial_length = len(pts)\n",
    "\n",
    "    #taking a random sample of indices (without replacement) of size k\n",
    "    random_indices = random.sample(range(len(data) - window_size), k = len(data) - window_size)\n",
    "\n",
    "    i = 0\n",
    "    for _ in range(initial_length):\n",
    "        # none of the temp data can be null, and the midpoint can't be a pointed labeled with the model type.\n",
    "        while any(pd.isnull(data.iloc[i:i+window_size]['temp'])) or (\n",
    "            not pd.isnull(data.iloc[i+window_size//2]['label']) and data.iloc[i+window_size//2]['label'].startswith(model_type)\n",
    "        ):\n",
    "            i += 1\n",
    "        pts.append([0] + data.iloc[i:i+window_size]['temp'].tolist())\n",
    "        i += 1\n",
    "\n",
    "    #tensors holding the label, followed by a list of 10 temperatures:\n",
    "    data = np.asarray(pts)\n",
    "    np.random.shuffle(data)\n",
    "\n",
    "    model = Sequential(\n",
    "        [\n",
    "            BatchNormalization(),\n",
    "            Dense(2**4, activation = 'relu', input_shape=(window_size,)),\n",
    "            Dense(1, activation = 'sigmoid')\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        loss='mse',\n",
    "        metrics=['mae'],\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        train[:,1:],\n",
    "        train[:,0],\n",
    "        epochs = int(4*1e5),\n",
    "        verbose = 0\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5a7b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(test_file, training_files):\n",
    "    data = allocate_data(training_files)    \n",
    "    start_model = train_model(data, 'start')\n",
    "    end_model = train_model(data, 'end')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b475cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(files)):\n",
    "    simulate(files[i], files[:i] + files[i+1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e63438b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
