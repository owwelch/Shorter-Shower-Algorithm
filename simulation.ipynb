{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e96599c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#note: temp readings are 20s apart\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Normalization\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "664fea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allocate_data(training_files):\n",
    "    dfs = {}\n",
    "    for file in training_files:\n",
    "        df = pd.read_excel(file, sheet_name=\"DATA\", usecols='C,D', skiprows = 1)\n",
    "        df.columns = ['temp', 'label']\n",
    "        df.loc[df.shape[0]] = [None, None]# to ensure that there are breaks between each recorded shower\n",
    "        dfs[file] = df\n",
    "    data = pd.concat(list(dfs.values()), ignore_index = True)# concatenating all our data into one big dataframe\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d14ab786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data, model_type):\n",
    "    if model_type == 'Start':\n",
    "        window_size = 19\n",
    "    elif model_type == 'End':\n",
    "        window_size = 25\n",
    "    #list where the first item is 1 for model_type and 0 for not model_type:\n",
    "    pts = []\n",
    "\n",
    "    for i, row in data.iterrows():\n",
    "        if not pd.isnull(row['label']):\n",
    "            if row['label'].startswith(model_type):\n",
    "                pts.append([1] + data.iloc[i-window_size//2:i+window_size//2+1]['temp'].tolist())\n",
    "\n",
    "    initial_length = len(pts)\n",
    "\n",
    "    #taking a random sample of indices (without replacement) of size k\n",
    "    random_indices = random.sample(range(len(data) - window_size), k = len(data) - window_size)\n",
    "\n",
    "    i = 0\n",
    "    for _ in range(initial_length):\n",
    "        # none of the temp data can be null, and the midpoint can't be a pointed labeled with the model type.\n",
    "        while any(pd.isnull(data.iloc[i:i+window_size]['temp'])) or (\n",
    "            not pd.isnull(data.iloc[i+window_size//2]['label']) and data.iloc[i+window_size//2]['label'].startswith(model_type)\n",
    "        ):\n",
    "            i += 1\n",
    "        pts.append([0] + data.iloc[i:i+window_size]['temp'].tolist())\n",
    "        i += 1\n",
    "\n",
    "    #tensors holding the label, followed by a list of 10 temperatures:\n",
    "    data = np.asarray(pts)\n",
    "    np.random.shuffle(data)\n",
    "\n",
    "    model = Sequential(\n",
    "        [\n",
    "            BatchNormalization(),\n",
    "            Dense(2**4, activation = 'relu', input_shape=(window_size,)),\n",
    "            Dense(1, activation = 'sigmoid')\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        loss='mse',\n",
    "        metrics=['mae'],\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        data[:,1:],\n",
    "        data[:,0],\n",
    "        epochs = int(4*1e5),\n",
    "        verbose = 0\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "430dbebb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1698133245.py, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [5]\u001b[1;36m\u001b[0m\n\u001b[1;33m    for i in rangen\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def simulate(test_file, training_files):\n",
    "    data = allocate_data(training_files)    \n",
    "    start_model = train_model(data, 'Start')\n",
    "    end_model = train_model(data, 'End')\n",
    "    test_data = pd.read_excel(test_file, sheet_name=\"DATA\", usecols='C,D', skiprows = 1)\n",
    "    test_data.columns = ['temp', 'label']\n",
    "    start_indices = []\n",
    "    end_indices = []\n",
    "    total_duration = sim_total_duration = shower_count = sim_shower_count = 0\n",
    "    sim_start_indices = []\n",
    "    sin_end_indices = []\n",
    "    for i in range(test_data.shape[0]):\n",
    "        if not pd.isnull(test_data['label'][i]):\n",
    "            if test_data['label'][i].startswith('Start'):\n",
    "                start_indices.append(i)\n",
    "            elif test_data['label'][i].startswith('End'):\n",
    "                end_indices.append(i)\n",
    "                total_duration += i - start_indices[-1]\n",
    "                shower_count += 1\n",
    "    window_sizes = (19, 25)\n",
    "    models = (start_model, end_model)\n",
    "    index_lists = (sim_start_indices, sim_end_indices)\n",
    "    Start = 0\n",
    "    End = 1\n",
    "    curr_test = Start\n",
    "    #last point detected should be an end point, so we must allow enough space to run the end model at all points.\n",
    "    for i in range(test_data.shape[0] - window_sizes[1] + 1):\n",
    "        if models[curr_test] == 1\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
