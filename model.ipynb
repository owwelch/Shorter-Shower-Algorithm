{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25cc4944",
   "metadata": {},
   "outputs": [],
   "source": [
    "#note: temp readings are 20s apart\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "import numpy as np\n",
    "\n",
    "os.chdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc1dab42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~$Copy of Dascomb 20461369 2019-12-02 18_07_58 -0500.xlsx\n"
     ]
    }
   ],
   "source": [
    "dfs = []# list of dataframes\n",
    "\n",
    "for folder in os.listdir():\n",
    "    if os.path.isdir(folder):\n",
    "        os.chdir(folder)\n",
    "        for file in os.listdir():\n",
    "            try:\n",
    "                df = pd.read_excel(file, sheet_name=\"DATA\", usecols='C,D', skiprows = 1)\n",
    "                df.loc[df.shape[0]] = [None, None]# to ensure that there are breaks between each recorded shower\n",
    "                dfs.append(df)\n",
    "            except:\n",
    "                print(file)\n",
    "        os.chdir('..')\n",
    "\n",
    "\n",
    "data = pd.concat(dfs, ignore_index = True)# concatenating all data into one dataframe\n",
    "data.columns = ['temp', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8b09ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_pts = []#list where the first item is 1 for start and 0 for not start\n",
    "end_pts = []#same list but for ends\n",
    "for i, row in data.iterrows():\n",
    "    if not pd.isnull(row['label']):\n",
    "        if row['label'].startswith('Start'):\n",
    "            start_pts.append([1] + data.iloc[i-4:i+5]['temp'].tolist())\n",
    "        if row['label'].startswith('End'):\n",
    "            end_pts.append([1] + data.iloc[i-4:i+5]['temp'].tolist())\n",
    "            \n",
    "initial_length = len(start_pts)\n",
    "if initial_length != len(end_pts):\n",
    "    print(\"inconsistent labels!\")\n",
    "\n",
    "random_start_indices = random.sample(range(len(data) - 9), k =  len(data) - 9)\n",
    "random_end_indices = random.sample(range(len(data) - 9), k = len(data) - 9)\n",
    "\n",
    "for i in random_start_indices:\n",
    "    if not (any(pd.isnull(data.iloc[i:i+9]['temp'])) or\n",
    "            (not pd.isnull(data.iloc[i+3]['label']) and data.iloc[i+3]['label'].startswith('Start'))):\n",
    "        start_pts.append([0] + data.iloc[i:i+9]['temp'].tolist())\n",
    "        if len(start_pts) == initial_length * 2:\n",
    "            break\n",
    "\n",
    "for i in random_end_indices:\n",
    "    if not (any(pd.isnull(data.iloc[i:i+9]['temp'])) or\n",
    "            (not pd.isnull(data.iloc[i+3]['label']) and data.iloc[i+3]['label'].startswith('End'))):\n",
    "        end_pts.append([0] + data.iloc[i:i+9]['temp'].tolist())\n",
    "        if len(end_pts) == initial_length * 2:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18f7c562",
   "metadata": {},
   "outputs": [],
   "source": [
    "#double peak to end length for window length\n",
    "#try 1 hidden layer with multiples of 2 neurons\n",
    "#try adjusting the learning rate\n",
    "#set epochs to a big number (like 2000)\n",
    "#look at decision trees for faster results if you want\n",
    "#put normalization as preprocessing (get all values between 0 and 1 by subtracting min, dividing by max, or something like that....?)\n",
    "#throw out batchnormalization for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23ed0fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_data = tf.convert_to_tensor(start_pts)#tensors holding the label, followed by a list of 10 temperatures\n",
    "start_data = tf.random.shuffle(start_data)\n",
    "\n",
    "end_data = tf.convert_to_tensor(end_pts)\n",
    "end_data = tf.random.shuffle(end_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02e6837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_length = start_data.shape[0]\n",
    "\n",
    "start_train = start_data[:int(data_length * .7)]\n",
    "start_val = start_data[int(data_length * .7):int(data_length * .85)]\n",
    "start_test = start_data[int(data_length * .85):]\n",
    "\n",
    "end_train = end_data[:int(data_length * .7)]\n",
    "end_val = end_data[int(data_length * .7):int(data_length * .85)]\n",
    "end_test = end_data[int(data_length * .85):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "116ccc94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3/3 [==============================] - 2s 3ms/step - loss: 0.3028 - mae: 0.5049\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2798 - mae: 0.4927\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2743 - mae: 0.4925\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2672 - mae: 0.4879\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2725 - mae: 0.4959\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2673 - mae: 0.4936\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2567 - mae: 0.4854\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2637 - mae: 0.4961\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2519 - mae: 0.4871\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2553 - mae: 0.4906\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2518 - mae: 0.4902\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2516 - mae: 0.4910\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2529 - mae: 0.4935\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2458 - mae: 0.4884\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2453 - mae: 0.4897\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2457 - mae: 0.4893\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2453 - mae: 0.4893\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2439 - mae: 0.4892\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2385 - mae: 0.4830\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2431 - mae: 0.4884\n"
     ]
    }
   ],
   "source": [
    "start_model = Sequential(\n",
    "    [\n",
    "        BatchNormalization(),\n",
    "        Dense(16, activation = 'relu', input_shape=(10,)),\n",
    "        Dense(16, activation = 'relu'),\n",
    "        Dense(1, activation = 'sigmoid')\n",
    "    ]\n",
    ")\n",
    "\n",
    "start_model.compile(loss='mse', metrics=['mae'])\n",
    "start_model.fit(start_train[:,1:], start_train[:,0], epochs=20)\n",
    "start_val_predicted = start_model.predict(start_val[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92c0f8af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5012828"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.absolute(start_val_predicted[:,0] - start_val[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14ec48d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.1652 - mae: 0.3833\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1505 - mae: 0.3553\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1518 - mae: 0.3501\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1441 - mae: 0.3366\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1429 - mae: 0.3308\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1486 - mae: 0.3318\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1359 - mae: 0.3138\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1321 - mae: 0.3110\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1302 - mae: 0.3054\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1377 - mae: 0.3156\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1286 - mae: 0.3079\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1301 - mae: 0.3061\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1343 - mae: 0.3124\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1292 - mae: 0.3081\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1368 - mae: 0.3121\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1250 - mae: 0.3017\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1389 - mae: 0.3186\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1169 - mae: 0.2956\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1328 - mae: 0.3068\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1285 - mae: 0.3067\n"
     ]
    }
   ],
   "source": [
    "end_model = Sequential(\n",
    "    [\n",
    "        BatchNormalization(),\n",
    "        Dense(16, activation = 'relu', input_shape=(10,)),\n",
    "        Dense(16, activation = 'relu'),\n",
    "        Dense(1, activation = 'sigmoid')\n",
    "    ]\n",
    ")\n",
    "\n",
    "end_model.compile(loss='mse', metrics=['mae'])\n",
    "end_model.fit(end_train[:,1:], end_train[:,0], epochs=20)\n",
    "end_val_predicted = end_model.predict(end_val[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d9a4aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57142735"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.absolute(end_val_predicted[:,0] - end_val[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cca807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cde5fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03df2d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
