{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25cc4944",
   "metadata": {},
   "outputs": [],
   "source": [
    "#note: temp readings are 20s apart\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "\n",
    "os.chdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc1dab42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".DS_Store\n"
     ]
    }
   ],
   "source": [
    "dfs = []# list of dataframes\n",
    "\n",
    "for file in os.listdir():\n",
    "    try:\n",
    "        df = pd.read_excel(file, sheet_name=\"DATA\", usecols='C,D', skiprows = 1)\n",
    "        df.loc[df.shape[0]] = [None, None]# to ensure that there are breaks between each recorded shower\n",
    "        dfs.append(df)\n",
    "    except:\n",
    "        print(file)\n",
    "\n",
    "data = pd.concat(dfs, ignore_index = True)# concatenating all data into one dataframe\n",
    "data.columns = ['temp', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8b09ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_pts = []#list where the first item is 1 for start and 0 for not start\n",
    "end_pts = []#same list but for ends\n",
    "for i, row in data.iterrows():\n",
    "    if not pd.isnull(row['label']):\n",
    "        if row['label'].startswith('Start'):\n",
    "            start_pts.append([1] + data.iloc[i-4:i+5]['temp'].tolist())\n",
    "        if row['label'].startswith('End'):\n",
    "            end_pts.append([1] + data.iloc[i-4:i+5]['temp'].tolist())\n",
    "            \n",
    "initial_length = len(start_pts)\n",
    "if initial_length != len(end_pts):\n",
    "    print(\"inconsistent labels!\")\n",
    "\n",
    "random_start_indices = random.sample(range(len(data) - 9), k =  len(data) - 9)\n",
    "random_end_indices = random.sample(range(len(data) - 9), k = len(data) - 9)\n",
    "\n",
    "for i in random_start_indices:\n",
    "    if not (any(pd.isnull(data.iloc[i:i+9]['temp'])) or\n",
    "            (not pd.isnull(data.iloc[i+3]['label']) and data.iloc[i+3]['label'].startswith('Start'))):\n",
    "        start_pts.append([0] + data.iloc[i:i+9]['temp'].tolist())\n",
    "        if len(start_pts) == initial_length * 2:\n",
    "            break\n",
    "\n",
    "for i in random_end_indices:\n",
    "    if not (any(pd.isnull(data.iloc[i:i+9]['temp'])) or\n",
    "            (not pd.isnull(data.iloc[i+3]['label']) and data.iloc[i+3]['label'].startswith('End'))):\n",
    "        end_pts.append([0] + data.iloc[i:i+9]['temp'].tolist())\n",
    "        if len(end_pts) == initial_length * 2:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23ed0fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_data = tf.convert_to_tensor(start_pts)#tensors holding the label, followed by a list of 10 temperatures\n",
    "start_data = tf.random.shuffle(start_data)\n",
    "\n",
    "end_data = tf.convert_to_tensor(end_pts)\n",
    "end_data = tf.random.shuffle(end_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02e6837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_length = start_data.shape[0]\n",
    "\n",
    "start_train = start_data[:int(data_length * .7)]\n",
    "start_val = start_data[int(data_length * .7):int(data_length * .85)]\n",
    "start_test = start_data[int(data_length * .85):]\n",
    "\n",
    "end_train = end_data[:int(data_length * .7)]\n",
    "end_val = end_data[int(data_length * .7):int(data_length * .85)]\n",
    "end_test = end_data[int(data_length * .85):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "116ccc94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 6051.6504 - mae: 77.6081\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 6044.1099 - mae: 77.5595\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 6038.4209 - mae: 77.5230\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 6034.5439 - mae: 77.4981\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 6030.9663 - mae: 77.4755\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 6027.7788 - mae: 77.4552\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 6024.7275 - mae: 77.4358\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 6022.6982 - mae: 77.4225\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 6019.4219 - mae: 77.4021\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 6018.1128 - mae: 77.3938\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 6014.5679 - mae: 77.3710\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6013.0615 - mae: 77.3614\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 6011.6411 - mae: 77.3525\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 6011.3652 - mae: 77.3506\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 6007.3931 - mae: 77.3254\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6004.7515 - mae: 77.3087\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 6002.3774 - mae: 77.2932\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6003.9087 - mae: 77.3033\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6000.9092 - mae: 77.2838\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5998.9756 - mae: 77.2714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e88dd05490>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_model = Sequential(\n",
    "    [\n",
    "        BatchNormalization(),\n",
    "        Dense(16, activation = 'relu', input_shape=(10,)),\n",
    "        Dense(16, activation = 'relu'),\n",
    "        Dense(1, activation = 'sigmoid')\n",
    "    ]\n",
    ")\n",
    "\n",
    "start_model.compile(loss='mse', metrics=['mae'])\n",
    "start_model.fit(start_train[:,1:], start_train[:,1], epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d9a4aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'tuple'> input: (<tf.Tensor 'IteratorGetNext:0' shape=(None, 0) dtype=float32>,)\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\users\\bring\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\users\\bring\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\users\\bring\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\users\\bring\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"c:\\users\\bring\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\users\\bring\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 247, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential\" (type Sequential).\n    \n    Input 0 of layer \"batch_normalization_2\" is incompatible with the layer: expected axis 1of input shape to have value 9, but received input with shape (None, 0)\n    \n    Call arguments received:\n      • inputs=('tf.Tensor(shape=(None, 0), dtype=float32)',)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m start_val \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart_val\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m start_val\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[1;32mc:\\users\\bring\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\users\\bring\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1129\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m   1130\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\users\\bring\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\users\\bring\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\users\\bring\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\users\\bring\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"c:\\users\\bring\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\users\\bring\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 247, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential\" (type Sequential).\n    \n    Input 0 of layer \"batch_normalization_2\" is incompatible with the layer: expected axis 1of input shape to have value 9, but received input with shape (None, 0)\n    \n    Call arguments received:\n      • inputs=('tf.Tensor(shape=(None, 0), dtype=float32)',)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "start_val = model.predict([start_val[:,1:]])\n",
    "start_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70cde5fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mabsolute(y_test \u001b[38;5;241m-\u001b[39m y_predicted[\u001b[38;5;241m0\u001b[39m,:,\u001b[38;5;241m0\u001b[39m]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "np.mean(np.absolute(y_test - y_predicted[0,:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03df2d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
