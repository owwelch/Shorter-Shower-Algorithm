{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25cc4944",
   "metadata": {},
   "outputs": [],
   "source": [
    "#note: temp readings are 20s apart\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "import numpy as np\n",
    "\n",
    "os.chdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc1dab42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".DS_Store\n"
     ]
    }
   ],
   "source": [
    "dfs = []# list of dataframes\n",
    "\n",
    "for file in os.listdir():\n",
    "    try:\n",
    "        df = pd.read_excel(file, sheet_name=\"DATA\", usecols='C,D', skiprows = 1)\n",
    "        df.loc[df.shape[0]] = [None, None]# to ensure that there are breaks between each recorded shower\n",
    "        dfs.append(df)\n",
    "    except:\n",
    "        print(file)\n",
    "\n",
    "data = pd.concat(dfs, ignore_index = True)# concatenating all data into one dataframe\n",
    "data.columns = ['temp', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8b09ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_pts = []#list where the first item is 1 for start and 0 for not start\n",
    "end_pts = []#same list but for ends\n",
    "for i, row in data.iterrows():\n",
    "    if not pd.isnull(row['label']):\n",
    "        if row['label'].startswith('Start'):\n",
    "            start_pts.append([1] + data.iloc[i-4:i+5]['temp'].tolist())\n",
    "        if row['label'].startswith('End'):\n",
    "            end_pts.append([1] + data.iloc[i-4:i+5]['temp'].tolist())\n",
    "            \n",
    "initial_length = len(start_pts)\n",
    "if initial_length != len(end_pts):\n",
    "    print(\"inconsistent labels!\")\n",
    "\n",
    "random_start_indices = random.sample(range(len(data) - 9), k =  len(data) - 9)\n",
    "random_end_indices = random.sample(range(len(data) - 9), k = len(data) - 9)\n",
    "\n",
    "for i in random_start_indices:\n",
    "    if not (any(pd.isnull(data.iloc[i:i+9]['temp'])) or\n",
    "            (not pd.isnull(data.iloc[i+3]['label']) and data.iloc[i+3]['label'].startswith('Start'))):\n",
    "        start_pts.append([0] + data.iloc[i:i+9]['temp'].tolist())\n",
    "        if len(start_pts) == initial_length * 2:\n",
    "            break\n",
    "\n",
    "for i in random_end_indices:\n",
    "    if not (any(pd.isnull(data.iloc[i:i+9]['temp'])) or\n",
    "            (not pd.isnull(data.iloc[i+3]['label']) and data.iloc[i+3]['label'].startswith('End'))):\n",
    "        end_pts.append([0] + data.iloc[i:i+9]['temp'].tolist())\n",
    "        if len(end_pts) == initial_length * 2:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23ed0fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 11:31:36.574256: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "start_data = tf.convert_to_tensor(start_pts)#tensors holding the label, followed by a list of 10 temperatures\n",
    "start_data = tf.random.shuffle(start_data)\n",
    "\n",
    "end_data = tf.convert_to_tensor(end_pts)\n",
    "end_data = tf.random.shuffle(end_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02e6837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_length = start_data.shape[0]\n",
    "\n",
    "start_train = start_data[:int(data_length * .7)]\n",
    "start_val = start_data[int(data_length * .7):int(data_length * .85)]\n",
    "start_test = start_data[int(data_length * .85):]\n",
    "\n",
    "end_train = end_data[:int(data_length * .7)]\n",
    "end_val = end_data[int(data_length * .7):int(data_length * .85)]\n",
    "end_test = end_data[int(data_length * .85):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "116ccc94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.2746 - mae: 0.5030\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2635 - mae: 0.4938\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2547 - mae: 0.4850\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2498 - mae: 0.4833\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2482 - mae: 0.4818\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2401 - mae: 0.4779\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2325 - mae: 0.4729\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2333 - mae: 0.4717\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2295 - mae: 0.4690\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2372 - mae: 0.4763\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2245 - mae: 0.4648\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2270 - mae: 0.4660\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2225 - mae: 0.4631\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2317 - mae: 0.4710\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2262 - mae: 0.4646\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2234 - mae: 0.4603\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2180 - mae: 0.4566\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2197 - mae: 0.4587\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2255 - mae: 0.4633\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.2239 - mae: 0.4617\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1305f05e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "start_model = Sequential(\n",
    "    [\n",
    "        BatchNormalization(),\n",
    "        Dense(16, activation = 'relu', input_shape=(10,)),\n",
    "        Dense(16, activation = 'relu'),\n",
    "        Dense(1, activation = 'sigmoid')\n",
    "    ]\n",
    ")\n",
    "\n",
    "start_model.compile(loss='mse', metrics=['mae'])\n",
    "start_model.fit(start_train[:,1:], start_train[:,0], epochs=20)\n",
    "start_val_predicted = start_model.predict(start_val[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4a727a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4998656"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.absolute(start_val_predicted[:,0] - start_val[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aaceeeb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.2677 - mae: 0.5093\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2614 - mae: 0.5050\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2537 - mae: 0.5006\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2539 - mae: 0.5003\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2536 - mae: 0.4995\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2575 - mae: 0.5024\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2525 - mae: 0.4990\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2518 - mae: 0.4983\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2505 - mae: 0.4973\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2514 - mae: 0.4986\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2481 - mae: 0.4949\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2492 - mae: 0.4966\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2481 - mae: 0.4959\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2458 - mae: 0.4930\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2446 - mae: 0.4912\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2461 - mae: 0.4920\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2466 - mae: 0.4920\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2479 - mae: 0.4923\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2463 - mae: 0.4915\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2435 - mae: 0.4881\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1308c91f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "end_model = Sequential(\n",
    "    [\n",
    "        BatchNormalization(),\n",
    "        Dense(16, activation = 'relu', input_shape=(10,)),\n",
    "        Dense(16, activation = 'relu'),\n",
    "        Dense(1, activation = 'sigmoid')\n",
    "    ]\n",
    ")\n",
    "\n",
    "end_model.compile(loss='mse', metrics=['mae'])\n",
    "end_model.fit(end_train[:,1:], end_train[:,0], epochs=20)\n",
    "end_val_predicted = end_model.predict(end_val[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d9a4aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36628133"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.absolute(end_val_predicted[:,0] - end_val[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce115d22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cde5fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03df2d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
